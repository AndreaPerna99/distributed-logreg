# Distributed Classification via Logistic Regression with Gradient Tracking

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)  
Decentralized machine learning algorithm for logistic regression using Gradient Tracking across a network of agents.

---
## ğŸ“Œ Project Info
- ğŸ“ Course: Distributed Autonomous Systems
- ğŸ« University of Bologna
- ğŸ“… Year: 2025
---

## ğŸ§  About the Project

This project implements a **distributed classification** system using **Gradient Tracking (GT)** in a multi-agent framework. It is divided into three main parts:

- ğŸ”„ **Distributed Optimization** â€” Solving a quadratic consensus problem using Gradient Tracking.
- ğŸ§® **Centralized Classification** â€” Logistic regression via gradient descent on synthetic data.
- ğŸ›° **Distributed Classification** â€” Classifying data distributed across agents using Gradient Tracking.

Implemented in a fully interactive **Jupyter Notebook**, this project demonstrates the real-world applicability of decentralized learning algorithms for nonlinear classification tasks.
---

## ğŸ—‚ Project Structure

```
ğŸ“¦ distributed-logreg/
â”œ ğŸ““ DAS_Task1_Group3.ipynb                  # Jupyter Notebook
â”œ ğŸ“„ Task1.pdf                               # Notebook execution PDF
â”œ ğŸ“˜ report_group_03.pdf                     # Full project report (pages 7â€“18 relevant)
â”£ ğŸ“ images                                  # Folder for images
â”ƒ â”£ ğŸ“¸ task1_1.png                           # Plot of Distributed Optimization
â”ƒ â”£ ğŸ“¸ task1_2.png                           # Plot of Centralized Classification
â”£ â”£ ğŸ“¸ task1_3.png                           # Plot of Distributed Classification
â”œ ğŸ“„ README.md                               # You are here!
```                                                 
## âš™ï¸ How to Run

1. Move into the task folder:

```
$ cd Task1/
$ jupyter notebook
```

2. Open the notebook `DAS_Task1_Group3.ipynb` and run each section sequentially.

## ğŸ§ª Tasks Breakdown

### ğŸš€ Task 1.1 â€“ Distributed Optimization

- Implements Gradient Tracking on a network of agents solving a decentralized quadratic optimization problem.
- Agents reach consensus using a doubly-stochastic weighted graph.
- Test different topologies: cycle, path, star.
- Plots include agents' states, gradient norms, and cost convergence.

![Gradient Tracking](./images/task1_1.png)

### ğŸ§  Task 1.2 â€“ Centralized Classification

- Generate 2D datasets labeled by nonlinear conic functions (e.g., ellipse, parabola).
- Apply centralized Gradient Descent for logistic regression.
- Evaluate classification on train/test sets and compute key metrics.

![Logistic Regression](./images/task1_2.png)

### ğŸŒ Task 1.3 â€“ Distributed Classification

- Extend Task 1.1 and 1.2 to a fully distributed setting.
- Split data among agents with or without label noise.
- Use GT to minimize logistic loss collaboratively.
- Visualize decision boundaries and metric evolution.
- Classify with and without label noise and compare results.

![Distributed Classification](./images/task1_3.png)

## ğŸ“Š Output & Evaluation

- ğŸ“‰ Plots: Cost evolution, gradient norms, decision boundaries.
- ğŸ“‹ Metrics: Classification error, accuracy, precision, recall, F1-score (train & test).
- âœ… Distributed version matches centralized accuracy with small performance drop under noise.

## ğŸ“ Resources

- [ğŸ“˜ Full Report (PDF)](./report_group_03.pdf)
- [ğŸ“„ Notebook Output (PDF)](./Task1.pdf)

## ğŸ‘¨â€ğŸ“ Authors

Group 3 â€“ MSc Automation Engineering, University of Bologna

- Andrea Perna
- Gianluca Di Mauro
- Meisam Tavakoli

ğŸ“§ and.perna99@gmail.com

## ğŸ‘©â€ğŸ« Supervisors

- Prof. Giuseppe Notarstefano
- Prof. Ivano Notarnicola
- Dr. Lorenzo Pichierri

## ğŸ“œ License

All rights reserved. Educational use only.
