# Distributed Classification via Logistic Regression with Gradient Tracking

[![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)](https://www.python.org/)  
Decentralized machine learning algorithm for logistic regression using Gradient Tracking across a network of agents.

---

## ğŸ§  About the Project

This project implements a **distributed classification** system using **Gradient Tracking (GT)** in a multi-agent framework. It is divided into three main parts:

- ğŸ”„ **Distributed Optimization** â€” Solving a quadratic consensus problem using GT.
- ğŸ§® **Centralized Classification** â€” Logistic regression via gradient descent on synthetic data.
- ğŸ›° **Distributed Classification** â€” Classifying data distributed across agents using GT.

Implemented in a fully interactive **Jupyter Notebook**, this project demonstrates the real-world applicability of decentralized learning algorithms for nonlinear classification tasks. This project was developed as the first part of the final exam project for the Distributed Autonomous System course at the Master Degree in Automation Engineering, University of Bologna.
---

---

## ğŸ—‚ Project Structure

```
ğŸ“¦ distributed-logreg/
â”œ ğŸ““ DAS_Task1_Group3.ipynb                  # Jupyter Notebook
â”œ ğŸ“„ Task1.pdf                               # Notebook execution PDF
â”œ ğŸ“˜ report_group_03.pdf                     # Full project report (pages 7â€“18 relevant)
â”£ ğŸ“ images
â”ƒ â”£ ğŸ“¸ task1_1.png
â”ƒ â”£ ğŸ“¸ task1_2.png
â”£ â”£ ğŸ“¸ task1_3.png
â”œ ğŸ“„ README.md                                   # You are here!
```                                                 
## âš™ï¸ How to Run

1. Move into the task folder:

```
$ cd Task1/
$ jupyter notebook
```

2. Open the notebook `DAS_Task1_Group3.ipynb` and run each section sequentially.

## ğŸ§ª Tasks Breakdown

### ğŸš€ Task 1.1 â€“ Distributed Optimization

- Implements Gradient Tracking on a network of agents solving a decentralized quadratic optimization problem.
- Agents reach consensus using a doubly-stochastic weighted graph.
- Test different topologies: cycle, path, star.
- Plots include agents' states, gradient norms, and cost convergence.

![Gradient Tracking](./images/task1_1.png)

### ğŸ§  Task 1.2 â€“ Centralized Classification

- Generate 2D datasets labeled by nonlinear conic functions (e.g., ellipse, parabola).
- Apply centralized Gradient Descent for logistic regression.
- Evaluate classification on train/test sets and compute key metrics.

![Logistic Regression](./images/task1_2.png)

### ğŸŒ Task 1.3 â€“ Distributed Classification

- Extend Task 1.1 and 1.2 to a fully distributed setting.
- Split data among agents with or without label noise.
- Use GT to minimize logistic loss collaboratively.
- Visualize decision boundaries and metric evolution.
- Classify with and without label noise and compare results.

![Distributed Classification](./images/task1_3.png)

## ğŸ“Š Output & Evaluation

- ğŸ“‰ Plots: Cost evolution, gradient norms, decision boundaries.
- ğŸ“‹ Metrics: Classification error, accuracy, precision, recall, F1-score (train & test).
- âœ… Distributed version matches centralized accuracy with small performance drop under noise.

## ğŸ“ Resources

- [ğŸ“˜ Full Report (PDF)](./report_group_03.pdf)
- [ğŸ“„ Notebook Output (PDF)](./Task1.pdf)

## ğŸ‘¨â€ğŸ“ Authors

Group 3 â€“ MSc Automation Engineering, University of Bologna

- Andrea Perna
- Gianluca Di Mauro
- Meisam Tavakoli

ğŸ“§ andrea.perna3@studio.unibo.it

## ğŸ‘©â€ğŸ« Supervisors

- Prof. Giuseppe Notarstefano
- Prof. Ivano Notarnicola
- Dr. Lorenzo Pichierri

## ğŸ“œ License

All rights reserved. Educational use only.
